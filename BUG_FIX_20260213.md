# Critical Experimental Design Bug Fix - February 13, 2026

## Summary

A critical bug was discovered and fixed in `scripts/run_experimental_sweep.py` that invalidated all experimental results generated before commit `f82135c`.

## The Problem

### What Was Happening (INCORRECT)

The script was pre-summarizing all texts with each LLM before embedding:

1. For `None` summarizer: Embed **original texts** → Cluster
2. For `gpt-4o`: Summarize with GPT-4o → Embed **summaries** → Cluster  
3. For `gpt-4o-mini`: Summarize with GPT-4o-mini → Embed **summaries** → Cluster
4. For `gpt-5-chat`: Summarize with GPT-5-chat → Embed **summaries** → Cluster

**Problem**: Each summarizer operated in a completely different embedding space. The comparison was confounded - we were testing "which LLM produces summaries that happen to embed in a way that clusters well" rather than "which LLM makes better centroids during the clustering process."

### Code Evidence of Bug

From `run_experimental_sweep.py` (lines 847-875, before fix):

```python
if llm_deployment is not None:
    print(f"        Summarizing {len(sampled_texts)} texts with {summarizer_name}...")
    # Create paraphraser for batch summarization
    paraphraser = create_paraphraser_for_llm(llm_deployment, db)
    
    # Summarize each text individually
    summarized_texts = []
    for i, text in enumerate(sampled_texts):
        summary = paraphraser([text])
        summarized_texts.append(summary)
    
    texts_to_embed = summarized_texts  # BUG: Different texts per summarizer!
else:
    texts_to_embed = sampled_texts

# Fetch embeddings for the (possibly summarized) texts
embeddings = await fetch_embeddings_async(texts_to_embed, EMBEDDING_DEPLOYMENT, db)
```

## The Fix

### What Should Happen (CORRECT)

All summarizers should operate on the **same embedding space**:

1. Embed **original texts** once (shared embeddings)
2. For `None`: Cluster with shared embeddings, no LLM
3. For `gpt-4o`: Cluster with shared embeddings, GPT-4o influences **centroid updates only**
4. For `gpt-4o-mini`: Cluster with shared embeddings, GPT-4o-mini influences **centroid updates only**
5. For `gpt-5-chat`: Cluster with shared embeddings, GPT-5-chat influences **centroid updates only**

**Correct**: Now we're testing "which LLM makes better centroids during k-LLM-means clustering" which is the actual research question.

### Code After Fix

From `run_experimental_sweep.py` (lines 819-838, after fix):

```python
# CRITICAL: Embed original texts ONCE (shared across all summarizers)
# This ensures we're testing "which LLM makes better centroids"
# NOT "which LLM pre-summaries embed better"
print(f"      Fetching embeddings for {len(sampled_texts)} original texts...")
shared_embeddings = await fetch_embeddings_async(sampled_texts, EMBEDDING_DEPLOYMENT, db)
print(f"      [OK] Fetched {len(shared_embeddings)} embeddings (shared across all summarizers)")

# Run sweep for each LLM summarizer sequentially
# NOTE: All summarizers use the SAME embeddings from original texts
# LLM influence is ONLY during in-loop centroid updates via paraphraser
for llm_deployment in LLM_SUMMARIZERS:
    # ...
    embeddings = shared_embeddings  # Same embeddings for all!
    result = await run_single_sweep(sampled_texts, embeddings, llm_deployment, db)
```

And in `run_single_sweep` (line 706):

```python
result = run_sweep(
    texts, embeddings, SWEEP_CONFIG,
    paraphraser=paraphraser,
    embedder=None  # ALWAYS None - no in-loop embedding
)
```

## Impact

### Invalidated Results

All experimental pickle files generated before 2026-02-13 are **scientifically invalid**:

- Total files affected: 534+ pickle files
- Date range: 2026-02-07 to 2026-02-13
- Datasets: 20newsgroups (6cat, 10cat), dbpedia, yahoo_answers
- Status: **Must be archived and re-run**

### Expected Changes After Fix

With the correct experimental design, we expect:

1. **Fairer comparison**: All LLMs start from the same embedding space
2. **Different results**: Previous "high silhouette at k=2 for gpt-5-chat" may have been an artifact of pre-summarization
3. **True LLM influence**: Now measures only the quality of LLM-generated centroids, not embedding artifacts

## Action Items

1. ✅ **Fix implemented** (commit `f82135c`)
2. ⬜ **Archive invalid data**: Move all existing pickle files to `backup_invalid_presummarization_20260213/`
3. ⬜ **Document in backup**: Create README explaining the bug
4. ⬜ **Re-run full sweep**: Execute with corrected experimental design
5. ⬜ **Verify results**: Check that embeddings are identical across summarizers (validation script)

## Technical Details

### Why This Happened

The bug was introduced because:

1. Initial implementation in another agent's work misunderstood k-LLM-means
2. The "embed summaries" approach seems intuitive but is wrong
3. No validation step to check embedding identity across runs

### How k-LLM-means Should Work

From the algorithm design:

1. **Initialization**: Embed all texts once, apply PCA once
2. **Assignment step**: Assign points to nearest centroid (standard k-means)
3. **Update step**: For each cluster, find representative texts, **summarize with LLM**, **re-embed summaries** to get new centroid
4. **Iteration**: Repeat until convergence

The LLM's role is in step 3 (centroid update), **not** in step 1 (initial embedding).

### Why `embedder=embedder_sync if paraphraser else None` Is Correct

In the fixed code, we pass `embedder=embedder_sync if paraphraser else None` to `run_sweep`. This is correct because:

**When LLM is used (`paraphraser` is not None):**
- We pass BOTH `paraphraser` and `embedder` to `run_sweep`
- Inside `k_llmmeans`, during centroid updates, it will:
  1. Select representative texts from each cluster
  2. Summarize them with the LLM (paraphraser)
  3. Re-embed the summaries (embedder)
  4. Use these embeddings as the new centroid positions
- This is the core mechanism of k-LLM-means: LLM-influenced centroids

**When no LLM is used (`paraphraser` is None):**
- We pass `embedder=None`
- Standard k-means centroid updates (mean of assigned points)
- No summarization or re-embedding

**Key point:** The data point embeddings (from original texts) are computed ONCE outside the loop. The embedder is ONLY used for re-embedding LLM summaries during centroid updates, NOT for the data points themselves.

This ensures a fair comparison: all methods start with the same embedding space, and only the centroid quality differs.

## Commit Information

- **Commit**: `f82135c`
- **Date**: 2026-02-13
- **Files Changed**: `scripts/run_experimental_sweep.py` (1 file, +38/-68 lines)
- **Previous Commit**: `7c4eaa5` (Save work before fixing critical experimental design bug)

## References

- See `backup_invalid_identical_embeddings_20260213/README.md` for the first bug fix (embedding identity bug)
- This is the **second** critical bug in the experimental design
- Both bugs have now been fixed in commit `f82135c`
